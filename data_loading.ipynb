{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96f918d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\madire\n",
      "[nltk_data]     sathwik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7edcd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "file_path = r\"D:\\NLP\\Project\\bbc-news-data.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bdf5dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ce67044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'filename', 'title', 'content'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b51d40fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category filename                              title  \\\n",
       "0  business  001.txt  Ad sales boost Time Warner profit   \n",
       "1  business  002.txt   Dollar gains on Greenspan speech   \n",
       "2  business  003.txt  Yukos unit buyer faces loan claim   \n",
       "3  business  004.txt  High fuel prices hit BA's profits   \n",
       "4  business  005.txt  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                             content  \n",
       "0   Quarterly profits at US media giant TimeWarne...  \n",
       "1   The dollar has hit its highest level against ...  \n",
       "2   The owners of embattled Russian oil giant Yuk...  \n",
       "3   British Airways has blamed high fuel prices f...  \n",
       "4   Shares in UK drinks and food firm Allied Dome...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fd66bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'filename', 'title', 'text'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename content=text\n",
    "df.rename(columns={'content': 'text'}, inplace=True)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2407f32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df['text'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8b5a0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2225.000000\n",
       "mean      378.835955\n",
       "std       238.220755\n",
       "min        84.000000\n",
       "25%       240.000000\n",
       "50%       326.000000\n",
       "75%       466.000000\n",
       "max      4428.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word count per article\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "df['word_count'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39b202e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.608090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.719021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>248.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_sentences\n",
       "count    2225.000000\n",
       "mean       18.608090\n",
       "std        12.719021\n",
       "min         4.000000\n",
       "25%        12.000000\n",
       "50%        16.000000\n",
       "75%        22.000000\n",
       "max       248.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence Tokenization\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "df['sentences'] = df['text'].apply(lambda x: sent_tokenize(str(x)))\n",
    "df['num_sentences'] = df['sentences'].apply(len)\n",
    "\n",
    "df[['num_sentences']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b96b3195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\madire\n",
      "[nltk_data]     sathwik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\madire\n",
      "[nltk_data]     sathwik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\madire\n",
      "[nltk_data]     sathwik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text Processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40ca9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword removal Lemmatization A preprocessing function Applied preprocessing to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3341db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5878f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    words = word_tokenize(sentence)   # ✅ correct function\n",
    "    \n",
    "    words = [\n",
    "        lemmatizer.lemmatize(word)\n",
    "        for word in words\n",
    "        if word.isalpha() and word not in stop_words\n",
    "    ]\n",
    "    \n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33f81419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7532a436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Google,\n",
      "Processed: ['quarterly', 'profit', 'u', 'medium', 'giant', 'timewarner', 'jumped', 'three', 'month', 'december', 'firm', 'one', 'biggest', 'investor', 'google']\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = df['text'].iloc[0][:200]\n",
    "\n",
    "print(\"Original:\", sample_sentence)\n",
    "print(\"Processed:\", preprocess_sentence(sample_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8331bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply to Dataset\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "df['sentences'] = df['text'].apply(lambda x: sent_tokenize(str(x)))\n",
    "df['processed_sentences'] = df['sentences'].apply(\n",
    "    lambda sents: [preprocess_sentence(s) for s in sents]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d863de",
   "metadata": {},
   "source": [
    "Text preprocessing was performed before summarization. This included stopword removal and lemmatization to reduce noise and normalize word forms, ensuring accurate sentence scoring during summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05bc6f6",
   "metadata": {},
   "source": [
    "# Building \n",
    "# model 1 Frequency-Based  extractive Summarization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc2ba1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "# Frequency-Based Summarizer Function\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def frequency_based_summarizer(text, num_sentences=5):\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    word_freq = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        for word in preprocess_sentence(sentence):\n",
    "            word_freq[word] += 1\n",
    "\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in preprocess_sentence(sentence):\n",
    "            sentence_scores[i] = sentence_scores.get(i, 0) + word_freq[word]\n",
    "\n",
    "    # pick top sentence indices\n",
    "    top_indices = sorted(\n",
    "        sentence_scores,\n",
    "        key=sentence_scores.get,\n",
    "        reverse=True\n",
    "    )[:num_sentences]\n",
    "\n",
    "    # restore original order\n",
    "    top_indices.sort()\n",
    "\n",
    "    return \" \".join([sentences[i] for i in top_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3838a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f787ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TEXT (first 400 chars):\n",
      "\n",
      " Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which o\n",
      "\n",
      "SUMMARY:\n",
      "\n",
      "Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue.\n"
     ]
    }
   ],
   "source": [
    "sample_text = df['text'].iloc[0]\n",
    "\n",
    "print(\"Original TEXT (first 400 chars):\\n\")\n",
    "print(sample_text[:400])\n",
    "print(\"\\nSUMMARY:\\n\")\n",
    "\n",
    "print(frequency_based_summarizer(sample_text, num_sentences=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
